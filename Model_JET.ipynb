{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "Learn to use visualization techniques to study:\n",
    "1. missing data\n",
    "2. distributions\n",
    "3. correlation heatmaps\n",
    "4. pairplots,\n",
    "5. t-SNE\n",
    "\n",
    "pre-proc:\n",
    "1. use catboost for categoric data\n",
    "\n",
    "model: \n",
    "\n",
    "# tal todo\n",
    "1. Anamaly detection algo, price, or Best using the pipe class\n",
    "2. check anomaly+ catboost\n",
    "3. check pipes + transform all\n",
    "4. predict with stacking\n",
    "5. hyper paramentr tuning\n",
    "# efrat todo\n",
    "5. one-hot to categoric\n",
    "6. split to different models for low and high prices\n",
    "7. check reressions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v5mm4amQRrm",
    "papermill": {
     "duration": 0.010092,
     "end_time": "2023-03-07T06:21:39.774967",
     "exception": false,
     "start_time": "2023-03-07T06:21:39.764875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# JET House Prices Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instruction\n",
    "## Part 1:\n",
    "[Model submission is done through Kaggle]\n",
    "Part 1 - EDA\n",
    "1. Which 3 features have the highest number of missing values\n",
    "2. How the price behave over the years?\n",
    "3. Plot the the feature distribution using histograms\n",
    "4. Compute and order the features by their correlation with label\n",
    "5. Add more EDA that will help you understand the data and support your modeling decisions\n",
    "\n",
    "Part 2 - baseline\n",
    "1. Train the simplest baseline model possible\n",
    "2. submit your baseline results and share the results\n",
    "\n",
    "## Part 2:\n",
    "[Model submission is done through Kaggle]\n",
    "Your solution:  go wild and build the best performing model!Which model you choose and why (relate to relevant EDA)?\n",
    "Choose a validation creation process, why you choose it? what is the baseline performance?\n",
    "Which smart tricks you used to boost your model performance?\n",
    "Describe potential generalization issues (e.g. overfit/underfit)? How can you handle these?\n",
    "submit your model and improve your rank in the leaderboard!\n",
    "\n",
    "Deliverables\n",
    "A final submission and score of you team in the leaderboard\n",
    "Working and easy to follow notebook with the 3 parts completed and that produce your best submission.\n",
    "Slides explaining your project: \n",
    "1. EDA\n",
    "2. decision made\n",
    "3. feature analysis\n",
    "4. validation\n",
    "5. modeling\n",
    "6. etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVOXAyXl3-fA",
    "papermill": {
     "duration": 0.008317,
     "end_time": "2023-03-07T06:21:39.809564",
     "exception": false,
     "start_time": "2023-03-07T06:21:39.801247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGmyjJJatzBZ",
    "papermill": {
     "duration": 8.300496,
     "end_time": "2023-03-07T06:21:48.118668",
     "exception": false,
     "start_time": "2023-03-07T06:21:39.818172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Comment this if the data visualisations doesn't work on your side\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printt(df,Name=None,verbose=True):    \n",
    "    if verbose==True:\n",
    "        print('----------------------')\n",
    "        if Name!=None:\n",
    "            print(Name)\n",
    "        if isinstance(df, dict):\n",
    "            for key, value in df.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(df)\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(y, y_pred,verbose=True,addline = True):\n",
    "    if verbose==True:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.scatter(y, y_pred, color='blue')\n",
    "        plt.title('True vs Predicted Values')\n",
    "        plt.xlabel('True Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        if addline: plt.plot([min(y), max(y)], [min(y), max(y)], color='red') # Line for perfect predictions\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full test set shape is (1459, 80)\n",
      "Full train dataset shape is (1460, 81)\n"
     ]
    }
   ],
   "source": [
    "test_file_path = \"project/test.csv\"\n",
    "train_file_path = \"project/train.csv\"\n",
    "testset_df = pd.read_csv(test_file_path)\n",
    "dataset_df = pd.read_csv(train_file_path)\n",
    "print(\"Full test set shape is {}\".format(testset_df.shape))\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n",
    "id_file = testset_df['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Value Counts for Each Categorical Feature:\n",
      "Neighborhood     25\n",
      "Exterior2nd      16\n",
      "Exterior1st      15\n",
      "SaleType          9\n",
      "Condition1        9\n",
      "Condition2        8\n",
      "HouseStyle        8\n",
      "RoofMatl          8\n",
      "Functional        7\n",
      "Foundation        6\n",
      "GarageType        6\n",
      "Heating           6\n",
      "BsmtFinType2      6\n",
      "BsmtFinType1      6\n",
      "SaleCondition     6\n",
      "RoofStyle         6\n",
      "BldgType          5\n",
      "GarageCond        5\n",
      "GarageQual        5\n",
      "Electrical        5\n",
      "HeatingQC         5\n",
      "LotConfig         5\n",
      "MSZoning          5\n",
      "ExterCond         5\n",
      "BsmtExposure      4\n",
      "BsmtCond          4\n",
      "ExterQual         4\n",
      "BsmtQual          4\n",
      "KitchenQual       4\n",
      "LandContour       4\n",
      "LotShape          4\n",
      "LandSlope         3\n",
      "GarageFinish      3\n",
      "PavedDrive        3\n",
      "Utilities         2\n",
      "Street            2\n",
      "CentralAir        2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_columns = ['MSZoning', 'Street', 'LotShape', 'LandContour',\n",
    "                   'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
    "                   'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "                   'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n",
    "                   'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                   'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                   'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    "                   'Functional', 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "                   'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
    "\n",
    "# Assuming df is your DataFrame containing your data\n",
    "# Assuming cat_cols is a list of column names corresponding to categorical features\n",
    "\n",
    "# Filter the DataFrame to include only categorical features\n",
    "cat_df = dataset_df[categorical_columns]\n",
    "\n",
    "# Count unique values for each categorical feature\n",
    "unique_value_counts = cat_df.nunique()\n",
    "\n",
    "# Sort the unique value counts in descending order\n",
    "unique_value_counts_sorted = unique_value_counts.sort_values(ascending=False)\n",
    "\n",
    "# Print the unique value counts for each categorical feature\n",
    "print(\"Unique Value Counts for Each Categorical Feature:\")\n",
    "print(unique_value_counts_sorted)\n",
    "\n",
    "# Visualize the distribution of unique values for the top N categorical features\n",
    "top_n = 10  # Number of top categorical features to visualize\n",
    "top_features = unique_value_counts_sorted.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features.plot(kind='bar')\n",
    "plt.title(f'Top {top_n} Categorical Features by Unique Value Count')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Unique Value Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['SalePrice'] = np.log(dataset_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    dataset_df['MSSubClass'] = dataset_df['MSSubClass'].apply(str)\n",
    "    dataset_df['MoSold'] = dataset_df['MoSold'].astype(str)\n",
    "    testset_df['MSSubClass'] = testset_df['MSSubClass'].apply(str)\n",
    "    testset_df['MoSold'] = testset_df['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allset_df = pd.concat([dataset_df, testset_df]).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features_df = dataset_df.select_dtypes(include='number')\n",
    "# numeric_features_df['LotFrontage'] = dataset_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "# for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "#     numeric_features_df[col] = numeric_features_df[col].fillna(0)\n",
    "# numeric_features_df = numeric_features_df.fillna(numeric_features_df.mean())\n",
    "# scaler = StandardScaler()\n",
    "# standardized_data = pd.DataFrame(scaler.fit_transform(numeric_features_df), columns=numeric_features_df.columns, index=numeric_features_df.index)\n",
    "# isloation_clf = IsolationForest(random_state=0).fit(standardized_data)\n",
    "# isloation_clf.predict(standardized_data)\n",
    "# iso_scores = isloation_clf.score_samples(standardized_data)\n",
    "# iso_scores = pd.DataFrame({'score': iso_scores}, index=standardized_data.index)\n",
    "# combined_df = pd.concat([iso_scores, standardized_data], axis=1).sort_values('score')\n",
    "# combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import OneClassSVM\n",
    "# svm_clf = OneClassSVM(nu=0.01).fit(standardized_data)\n",
    "# svm_scores = svm_clf.score_samples(standardized_data)\n",
    "# svm_scores = pd.DataFrame({'score': svm_scores}, index=standardized_data.index)\n",
    "# combined_df = pd.concat([svm_scores, standardized_data], axis=1).sort_values('score')\n",
    "# combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# scl = StandardScaler(with_mean=True,with_std=True)\n",
    "# pca.fit(scl.fit_transform(standardized_data))\n",
    "\n",
    "# def reduce_dim_reconstruct(data):\n",
    "#   #Reduce the dimension, reconstruct. Standrtize data.\n",
    "#   return scl.inverse_transform(pca.inverse_transform(pca.transform(scl.transform(data))))\n",
    "\n",
    "# pca_scores = -1* ((standardized_data - reduce_dim_reconstruct(standardized_data)) ** 2).sum(axis=1)\n",
    "# pca_scores = pd.DataFrame({'score': pca_scores}, index=standardized_data.index)\n",
    "# combined_df = pd.concat([pca_scores, standardized_data], axis=1).sort_values('score')\n",
    "# combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_scores = pd.DataFrame({'score': (svm_scores.score.rank()+iso_scores.score.rank() + pca_scores.score.rank())/3},index=standardized_data.index).sort_values('score')\n",
    "\n",
    "# combined_df = pd.concat([ensemble_scores, standardized_data], axis=1).sort_values('score')\n",
    "# combined_df.head(20)\n",
    "# combined_df['score'].values[:15]\n",
    "# combined_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 523,  495,  632,   30, 1298, 1324,  462,  916,  968,  812,  185,\n",
       "        688,  588,  970,  410,  710, 1432, 1182, 1453, 1122, 1062,  313,\n",
       "        581,  714,  666,  874, 1181,  898,  328,  479,  803,  589,  774,\n",
       "        142, 1163,  608,  681, 1279,   13,  431,  691, 1211,  533,  496,\n",
       "        488, 1328,  972, 1046,   66,  318], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_error = pd.read_csv(\"high_error.csv\")\n",
    "high_error['Sample'].values[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PerformAnomalyDrop = False\n",
    "if PerformAnomalyDrop == True:\n",
    "    indices_to_show = [523, 1298, 30, 88, 462, 632, 1324]\n",
    "    entries_to_show = dataset_df.loc[indices_to_show]\n",
    "    indices_to_throw = [1298, 1182, 1386, 691, 185, 496 ]\n",
    "    indices_to_throw = [898, 581, 1062, 589, 462, 431, 496, 13, 691, 916, 313, 1211]\n",
    "    indices_to_throw = [495, 30, 916]\n",
    "    #indices_to_throw = combined_df.index.values[:6]\n",
    "    #dataset_df = dataset_df[dataset_df.GrLivArea < 4500]\n",
    "    dataset_df =  dataset_df.drop(indices_to_throw)\n",
    "    dataset_df.reset_index(drop=True, inplace=True)\n",
    "    y = dataset_df['SalePrice'].reset_index(drop=True)\n",
    "    id_file = testset_df['Id']\n",
    "    entries_to_show[['MiscVal', 'SalePrice']]\n",
    "    #entries_to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.072541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.254863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.493130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>11.864462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>11.901583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal  12.247694  \n",
       "1         5   2007        WD         Normal  12.109011  \n",
       "2         9   2008        WD         Normal  12.317167  \n",
       "3         2   2006        WD        Abnorml  11.849398  \n",
       "4        12   2008        WD         Normal  12.429216  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal  12.072541  \n",
       "1456      2   2010        WD         Normal  12.254863  \n",
       "1457      5   2010        WD         Normal  12.493130  \n",
       "1458      4   2010        WD         Normal  11.864462  \n",
       "1459      6   2008        WD         Normal  11.901583  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_quantiles = combined_df['score'].quantile([0.01, 0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "# custom_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'dataset_df' is your DataFrame\n",
    "y = dataset_df['SalePrice']\n",
    "X = dataset_df.drop('SalePrice', axis=1)\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Assuming numerical_features is a list of column names of numerical features\n",
    "    numerical_features = dataset_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Create box plots for all numerical features\n",
    "    # for feature in numerical_features:\n",
    "    #     plt.figure(figsize=(8, 6))\n",
    "    #     sns.boxplot(x=dataset_df[feature])\n",
    "    #     plt.title(f'Box plot of {feature}')\n",
    "    #     plt.show()\n",
    "    # Create box plots and scatter plots for each numerical feature\n",
    "    for feature in numerical_features:\n",
    "        # Create a new figure with two subplots in one row\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    \n",
    "        # Box plot\n",
    "        sns.boxplot(x=dataset_df[feature], ax=axes[0])\n",
    "        axes[0].set_title(f'Box plot of {feature}')\n",
    "    \n",
    "        # Scatter plot\n",
    "        sns.scatterplot(x=dataset_df[feature], y=dataset_df['SalePrice'], ax=axes[1])\n",
    "        axes[1].set_title(f'Scatter plot of {feature} vs SalePrice')\n",
    "        axes[1].set_xlabel(feature)\n",
    "        axes[1].set_ylabel('SalePrice')\n",
    "    \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "    \n",
    "        # Show the plots\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTnx8h9i416m",
    "papermill": {
     "duration": 0.008651,
     "end_time": "2023-03-07T06:21:48.263024",
     "exception": false,
     "start_time": "2023-03-07T06:21:48.254373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is composed of 81 columns and 1460 entries. We can see all 81 dimensions of our dataset by printing out the first 3 entries using the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explain_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass: Identifies the type of dwelling involved in the sale.\n",
      "\n",
      "20\t1-STORY 1946 & NEWER ALL STYLES\n",
      "30\t1-STORY 1945 & OLDER\n",
      "40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
      "45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
      "50\t1-1/2 STORY FINISHED ALL AGES\n",
      "60\t2-STORY 1946 & NEWER\n",
      "70\t2-STORY 1945 & OLDER\n",
      "75\t2-1/2 STORY ALL AGES\n",
      "80\tSPLIT OR MULTI-LEVEL\n",
      "85\tSPLIT FOYER\n",
      "90\tDUPLEX - ALL STYLES AND AGES\n",
      "120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
      "150\t1-1/2 STORY PUD - ALL AGES\n",
      "160\t2-STORY PUD - 1946 & NEWER\n",
      "180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
      "190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def explain_feature(feature_name, file_path=\"project/data_description.txt\"):\n",
    "    feature_name_lower = feature_name.lower()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        collecting = False\n",
    "        for line in lines:\n",
    "            if feature_name_lower in line.lower():\n",
    "                collecting = True\n",
    "            elif collecting and \":\" in line and not line.lower().startswith(feature_name_lower):\n",
    "                # If we're collecting and encounter a line with a colon that doesn't start with the feature name,\n",
    "                # it's likely the start of another feature's description.\n",
    "                break\n",
    "            \n",
    "            if collecting:\n",
    "                print(line.strip())\n",
    "\n",
    "# Example usage\n",
    "explain_feature(\"MSSubClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_order_categoric_to_numeric(X,y=None,verbose=False):\n",
    "# Assuming X is your DataFrame\n",
    " if 0:\n",
    "    category_sets = [\n",
    "        set(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NotExist']),\n",
    "        set(['Gd', 'Av', 'Mn', 'No', 'NotExist']),\n",
    "        set(['GLQ','ALQ','BLQ','Rec','LwQ','Unf','NotExist']),\n",
    "        set(['Fin','RFn','Unf','NotExist']),\n",
    "        set(['GdPrv','MnPrv','GdWo','MnWw','NotExist']),\n",
    "    ]\n",
    "    titles = ['quality_mapping', 'access_mapping', 'basement_mapping', 'garage_mapping', 'fence_mapping']\n",
    "    \n",
    "    # Mappings\n",
    "    quality_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NotExist': 0}\n",
    "    access_mapping = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NotExist': 0}\n",
    "    basement_mapping = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NotExist': 0}\n",
    "    garage_mapping = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
    "    fence_mapping = {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'NotExist': 0}\n",
    "    \n",
    "    # Mapping from titles to actual mappings\n",
    "    mapping_dict = {\n",
    "        'quality_mapping': quality_mapping,\n",
    "        'access_mapping': access_mapping,\n",
    "        'basement_mapping': basement_mapping,\n",
    "        'garage_mapping': garage_mapping,\n",
    "        'fence_mapping': fence_mapping,\n",
    "    }\n",
    "    \n",
    "    # Select columns of object type\n",
    "    col_object = X.select_dtypes(include=['O']).columns.tolist()\n",
    "    \n",
    "    matching_categories = {}\n",
    "    for col in col_object:\n",
    "        vals = set(X[col].unique())\n",
    "        # Check which category set vals belongs to\n",
    "        for index, category_set in enumerate(category_sets):\n",
    "            if vals.issubset(category_set):  # Check if all elements of vals are in the category_set\n",
    "                matching_categories[col] = titles[index]                \n",
    "                break  # Exit the loop if a matching set is found\n",
    "\n",
    "    # Apply the matched mappings to the columns\n",
    "    X_ = X.copy()\n",
    "    for col, title in matching_categories.items():\n",
    "        if title in mapping_dict:\n",
    "            X_[col] = X[col].map(mapping_dict[title])\n",
    "\n",
    "    if verbose==True:\n",
    "        printt(len(matching_categories),'matching_categories')\n",
    "        print(list(matching_categories.keys()))\n",
    "        for col, title in matching_categories.items():\n",
    "            if y is not None and not y.empty:\n",
    "                categoric_analysis(X[[col]],y,True)\n",
    "            print(f\"{col}: {title} : {mapping_dict[title]}\")\n",
    "    \n",
    "    return X_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "number of categorical\n",
      "1\n",
      "----------------------\n",
      "categorical List\n",
      "['BldgType']\n",
      "----------------------\n",
      "BldgType\n",
      "\n",
      "1\n",
      "BldgType: Type of dwelling\n",
      "\n",
      "1Fam\tSingle-family Detached\n",
      "2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n",
      "Duplx\tDuplex\n",
      "TwnhsE\tTownhouse End Unit\n",
      "TwnhsI\tTownhouse Inside Unit\n",
      "\n",
      "        col     val ymean ystd  number ratio\n",
      "0  BldgType  2fmCon 11.73 0.28      31  2.12\n",
      "1  BldgType   Twnhs 11.77 0.31      43  2.95\n",
      "2  BldgType  Duplex 11.78 0.21      52  3.56\n",
      "3  BldgType    1Fam 12.05 0.41    1220 83.56\n",
      "4  BldgType  TwnhsE 12.06 0.32     114  7.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def categoric_analysis(X,y,verbose=False):\n",
    "    #col_object = X.select_dtypes(include=['O']).columns.tolist()\n",
    "    cols = X.columns.tolist()\n",
    "    #cols = X.columns.tolist()\n",
    "    printt(len(cols),'number of categorical',verbose=verbose)\n",
    "    printt(cols,'categorical List',verbose=verbose)\n",
    "    i=0\n",
    "    for col in cols:\n",
    "        i = i+1\n",
    "        vals = X[col].unique()        \n",
    "        cols = [col for _ in range(len(vals))]  # This will create a list with 'title' repeated\n",
    "        #print('\\n'.join(str(val) for val in vals))\n",
    "        ymean  = [np.mean(y[X[col] == val])  for val in vals]\n",
    "        ystd   = [np.std(y[X[col] == val])   for val in vals]\n",
    "        ratios = [np.mean(X[col] == val)*100         for val in vals]\n",
    "        numbers = [np.sum(X[col] == val)             for val in vals]\n",
    "\n",
    "        df = pd.DataFrame({'col': cols, 'val': vals, 'ymean': ymean, 'ystd': ystd,'number': numbers, 'ratio': ratios})\n",
    "        df.loc[pd.isna(vals), 'ratio'] = np.mean(X[col].isna())*100\n",
    "        df.loc[pd.isna(vals), 'number'] = np.sum(X[col].isna())\n",
    "        df.loc[pd.isna(vals), 'ymean'] = np.mean(y[X[col].isna()])\n",
    "        df.loc[pd.isna(vals), 'ystd'] = np.std(y[X[col].isna()])\n",
    "        df = df.sort_values(by='ymean', ascending=True).reset_index(drop=True)  # Use ascending=False for descending order\n",
    "        # This will apply the formatting and then convert the DataFrame to a string for printing\n",
    "        formatted_df_string = df.to_string(formatters={'ymean': \"{:.2f}\".format, 'ystd': \"{:.2f}\".format, 'ratio': \"{:.2f}\".format})\n",
    "        printt('',col,verbose=verbose)      \n",
    "        if verbose==True:        \n",
    "            print(i)\n",
    "            explain_feature(col)\n",
    "            print(formatted_df_string)        \n",
    "            plot_categoric(df,col)\n",
    "    return df\n",
    "\n",
    "def plot_categoric(df,col):\n",
    "        ymean = df['ymean'].values\n",
    "        ystd = df['ystd'].values\n",
    "        numbers = df['number'].values\n",
    "        vals = df['val'].values        \n",
    "            # Plotting\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, len(vals)))  # Generate distinct colors\n",
    "\n",
    "        for i, mean in enumerate(ymean):\n",
    "            # Generate x values\n",
    "            x = np.linspace(norm.ppf(0.01, loc=mean, scale=ystd[i]),\n",
    "                            norm.ppf(0.99, loc=mean, scale=ystd[i]), 100)\n",
    "            # Generate y values for Gaussian curve\n",
    "            y_gauss = norm.pdf(x, loc=mean, scale=ystd[i]) * numbers[i]  # Scale by 'num'\n",
    "            plt.plot(x, y_gauss, label=f'{vals[i]} (n={numbers[i]})', color=colors[i])\n",
    "\n",
    "        plt.title(f'{col}')\n",
    "        plt.legend()\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#categoric_analysis(X[['ExterQual']],y,True)\n",
    "#categoric_analysis(X[['Condition1']],y,True)\n",
    " \n",
    "manual_feature_importance = {\n",
    "    'not': ['Street','LandContour','Utilities','LotConfig','LandSlope','Condition2','RoofMatl','ExterCond','Heating','Functional','GarageQual','GarageCond','PavedDrive','PoolQC','Fence','MiscFeature'],\n",
    "    'low': ['Alley','Condition1','BsmtCond','BsmtFinType2','CentralAir','Electrical'],\n",
    "    'med': ['MSZoning','BldgType','HouseStyle','RoofStyle','Exterior1st','Exterior2nd','BsmtExposure','BsmtFinType1','SaleType','SaleCondition'],\n",
    "    'high': ['LotShape','Neighborhood','MasVnrType','ExterQual','Foundation','BsmtQual','HeatingQC','KitchenQual','FireplaceQu','GarageType','GarageFinish']\n",
    "}\n",
    "#example of use\n",
    "if 0:\n",
    "    categoric_analysis(X[manual_feature_importance['high']],y,True)\n",
    "if 1:\n",
    "    df = categoric_analysis(X[['BldgType']],y,True)\n",
    "if 0:\n",
    "    df = categoric_analysis(X[['MoSold','MSSubClass']],y,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSSubClass': {30: 11.717627406309452, 180: 11.717627406309452, 45: 11.717627406309452, 190: 11.717627406309452, 90: 11.717627406309452, 160: 11.717627406309452, 50: 11.717627406309452, 40: 12.036580782785146, 85: 12.036580782785146, 70: 12.036580782785146, 80: 12.036580782785146, 20: 12.036580782785146, 75: 12.292572463914874, 120: 12.292572463914874, 60: 12.292572463914874}}\n",
      "43 32\n",
      "----------------------\n",
      "0       12.292572\n",
      "1       12.036581\n",
      "2       12.292572\n",
      "3       12.036581\n",
      "4       12.292572\n",
      "          ...    \n",
      "1455    12.292572\n",
      "1456    12.036581\n",
      "1457    12.036581\n",
      "1458    12.036581\n",
      "1459    12.036581\n",
      "Name: MSSubClass, Length: 1460, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def categoric_to_numeric_maping(df,MinRatioPerGroup = 10 ,verbose=False):\n",
    "    #df = pd.DataFrame({'col': cols, 'val': vals, 'ymean': ymean, 'ystd': ystd,'number': numbers, 'ratio': ratios})\n",
    "    MinRatioPerGroup = 100/np.floor(100/MinRatioPerGroup)\n",
    "    # diveide to groups\n",
    "    sum_ratio = 0\n",
    "    group = 0\n",
    "    for i in range(len(df)):\n",
    "        sum_ratio = sum_ratio + df.loc[i,'ratio']        \n",
    "        df.loc[i,'group'] = group\n",
    "        if sum_ratio>=MinRatioPerGroup:\n",
    "           sum_ratio = 0\n",
    "           group = group + 1        \n",
    "    # add last group to prev if it's too small\n",
    "    last_group_indexes = (df['group'] == group)\n",
    "    if np.sum(df.loc[last_group_indexes,'ratio'])<MinRatioPerGroup:\n",
    "        df.loc[last_group_indexes,'group'] = group-1\n",
    "\n",
    "    # add last group to prev if it's too small\n",
    "    if np.sum(df.loc[last_group_indexes,'ratio'])<MinRatioPerGroup:        \n",
    "        df.loc[last_group_indexes,'group'] = group-1\n",
    "\n",
    "    NGroups = int(df['group'].max()) + 1\n",
    "    # calc mean y per group\n",
    "    for g in range(NGroups):\n",
    "        group_indexes = (df['group'] == g)\n",
    "        ymean_group = np.sum(df.loc[group_indexes,'ymean']*df.loc[group_indexes,'number'])/np.sum(df.loc[group_indexes,'number'])\n",
    "        df.loc[group_indexes,'ymean_group'] = ymean_group\n",
    "        df.loc[group_indexes,'number_group'] = np.sum(df.loc[group_indexes,'number'])\n",
    "        df.loc[group_indexes,'ratio_group'] = np.sum(df.loc[group_indexes,'ratio'])\n",
    "    #print(df)\n",
    "    val_to_ymean_map = df.set_index('val')['ymean_group'].to_dict()\n",
    "    val_to_group_map = df.set_index('val')['group'].to_dict()\n",
    "    return val_to_ymean_map,val_to_group_map\n",
    "\n",
    "\n",
    "def categoric_to_numeric_fit(X,y,categortic_Config_params,cols=None, JustCategoric=True,verbose=False):\n",
    "    MinRatioPerGroup = categortic_Config_params['MinRatioPerGroup']\n",
    "    if JustCategoric==True:\n",
    "        exist_cols = X.select_dtypes(include=['O']).columns.tolist()\n",
    "    else:\n",
    "        exist_cols = X.columns.tolist()\n",
    "\n",
    "    if cols is None:\n",
    "        cols = exist_cols\n",
    "    else:\n",
    "        filtered_cols = [col for col in cols if col in exist_cols]\n",
    "        cols = filtered_cols\n",
    "    categoric_map = dict()\n",
    "    for col in cols:\n",
    "        df = categoric_analysis(X[[col]],y,False)\n",
    "        val_to_ymean_map,val_togroup_map = categoric_to_numeric_maping(df,MinRatioPerGroup,verbose=verbose)   \n",
    "        if categortic_Config_params['replaceby']=='ymean':\n",
    "            categoric_map[col] = val_to_ymean_map\n",
    "        else:\n",
    "            categoric_map[col] = val_togroup_map  \n",
    "        printt(df,'df in categoric_to_numeric_fit',verbose=verbose)\n",
    "        printt(categoric_map,'categoric_map in categoric_to_numeric_fit',verbose=verbose)\n",
    "    return categoric_map\n",
    "def categoric_to_numeric_transform(X,categoric_map,verbose=False):\n",
    "    X_ = X.copy()\n",
    "    for col in categoric_map:\n",
    "        X_[col] = X_[col].map(categoric_map[col])        \n",
    "    return X_\n",
    "\n",
    "#ExampleOfuse\n",
    "if 1:\n",
    "    categortic_Config_params1 = dict()\n",
    "    categortic_Config_params1['MinRatioPerGroup'] = 15\n",
    "    categortic_Config_params1['replaceby'] = 'ymean' #'ymean', 'group_nember'\n",
    "    cols = manual_feature_importance['high']\n",
    "    categoric_map = categoric_to_numeric_fit(X,y,categortic_Config_params1,cols=cols,JustCategoric=True,verbose=False)\n",
    "    X_numeric = categoric_to_numeric_transform(X,categoric_map,verbose=False)\n",
    "    \n",
    "    col_to_map_num = ['MSSubClass']\n",
    "    categoric_map_num = categoric_to_numeric_fit(X_numeric,y,categortic_Config_params1,cols=col_to_map_num,JustCategoric=False,verbose=False)\n",
    "    print(categoric_map_num)\n",
    "    X_numeric = categoric_to_numeric_transform(X_numeric,categoric_map_num,verbose=False)\n",
    "    \n",
    "    col_object1 = X.select_dtypes(include=['O']).columns.tolist()\n",
    "    col_object2 = X_numeric.select_dtypes(include=['O']).columns.tolist()\n",
    "    print(len(col_object1),len(col_object2))\n",
    "    printt(X_numeric['MSSubClass'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre proccessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to remove NAs\n",
    "class drop_ID(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, verbose=False):        \n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y=None):\n",
    "        printt('','In drop_ID fit',verbose=self.verbose)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        printt(X.shape,'drop_ID in X.shape',verbose=self.verbose)\n",
    "        # Ensure 'Id' column is removed safely\n",
    "        if 'Id' in X.columns:\n",
    "            return X.drop('Id', axis=1)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imput_mean(X,mean):\n",
    "    for col in X.columns:        \n",
    "        X[col].fillna(mean, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imput_mean_mode(X,mean_mode):\n",
    "    # impute missing value by pre calc mean or mode :\n",
    "    for col in X.columns:        \n",
    "        X[col].fillna(mean_mode[col], inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imput_mean_per_Neighborhood(X,mean_per_Neighborhood,mean_mode,feature='Neighborhood'):\n",
    "    col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    for col in col_numeric:\n",
    "        row_index = pd.isna(X[col])\n",
    "        # Iterate over each row that contains NaN in the current column\n",
    "        for idx in X[row_index].index:\n",
    "            # Get the Neighborhood value for the current row\n",
    "            NeighborhoodVal = X.loc[idx, feature]            \n",
    "            # If the combination exists in the mean_per_Neighborhood, fill NaN with the mean value\n",
    "            if (NeighborhoodVal, col) in mean_per_Neighborhood:\n",
    "                X.loc[idx, col] = mean_per_Neighborhood[NeighborhoodVal, col]\n",
    "            else:\n",
    "                X.loc[idx, col] = mean_mode[col]\n",
    "    return X\n",
    "\n",
    "def calc_mean_Pef_feature(X,feature='Neighborhood'):\n",
    "    col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    mean_per_Neighborhood = X.groupby(feature)[col_numeric].mean()\n",
    "    return mean_per_Neighborhood\n",
    "\n",
    "if 0:\n",
    "    mean_per_Neighborhood = calc_mean_Pef_feature(X,feature='Neighborhood')\n",
    "    X_New_ = imput_mean_per_Neighborhood(X,mean_per_Neighborhood,feature='Neighborhood')\n",
    "    printt(mean_per_Neighborhood,'combined_stats_perNeighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def calc_mean_mode(X):\n",
    "    # find the mean of numrical columns and the mode of object columns\n",
    "    # return :\n",
    "    # combined_stats = mean amd mode in the same shape as orign,\n",
    "    # col_numeric,col_object =list of numeric and obkect coumln names\n",
    "    col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    col_object = X.select_dtypes(include=['O']).columns.tolist()\n",
    "    printt(col_numeric,'col_numeric',False)\n",
    "    printt(col_object,'col_object',False)\n",
    "    # save the mean and the mode for later imputation\n",
    "    means = X[col_numeric].mean()\n",
    "    modes = X[col_object].mode().iloc[0]\n",
    "    # Step 3: Combine results, maintaining the original arrangement\n",
    "    combined_stats = pd.Series(dtype=object)\n",
    "    for col in X.columns:\n",
    "        if col in means:\n",
    "            combined_stats[col] = means[col]\n",
    "        elif col in modes:\n",
    "            combined_stats[col] = modes[col]\n",
    "    return combined_stats,col_numeric,col_object\n",
    "    \n",
    "if 0:\n",
    "    combined_stats = calc_mean_mode(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_col(X,threshold=None,verbose=False):\n",
    "    # drop col with na in amount more than threshold\n",
    "    if threshold is not None:\n",
    "        thresh = len(X)*threshold//1        \n",
    "        na_counts    = X.isna().sum()\n",
    "        columns_to_keep_ = na_counts[na_counts < thresh].index\n",
    "        columns_to_remove_ = na_counts[na_counts >= thresh].index\n",
    "    else:\n",
    "        columns_to_keep_ = X.columns\n",
    "        columns_to_remove_ = pd.Index([])        \n",
    "\n",
    "    if verbose==True:\n",
    "        nan_counts  = X.isna().sum().sort_values(ascending=False).head(20)/len(X)*100\n",
    "        print(f\"features with the highest number of missing values in %\")\n",
    "        print(f\"{nan_counts}%\")\n",
    "        printt(len(columns_to_keep_),'len(columns_to_keep_)',verbose=verbose)\n",
    "        printt(len(columns_to_remove_),'len(columns_to_remove_)',verbose=verbose)\n",
    "        if len(columns_to_remove_)>0:\n",
    "            printt(columns_to_remove_,'columns_to_remove_',verbose=verbose)           \n",
    "\n",
    "    return columns_to_keep_,columns_to_remove_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row_nan_counts(X,verbose=False):\n",
    "    # print number of Rows with missing values\n",
    "    row_nan_counts = X.isna().sum(axis=1) \n",
    "    top_row_nan_counts = row_nan_counts.sort_values(ascending=False)\n",
    "    if verbose==True:\n",
    "        print(\"number of Rows with missing values:\")\n",
    "        print(top_row_nan_counts.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missingVal_groups(X,verbose=False):\n",
    "    row_nan_counts = X.isna().sum(axis=1) \n",
    "    rows_with_missing_values = X[row_nan_counts >0]\n",
    "    unique_missing_column_groups = set()\n",
    "    # Iterate through rows and identify unique groups of missing columns\n",
    "    for _, row in rows_with_missing_values.iterrows():\n",
    "        # Extract groups of 5 columns\n",
    "        groups = tuple(row.index[row.isna()])\n",
    "        # Add the unique group to the set\n",
    "        unique_missing_column_groups.add(groups)\n",
    "    \n",
    "    # Sort the unique groups by their length\n",
    "    sorted_unique_missing_column_groups = sorted(unique_missing_column_groups, key=lambda x: len(x))\n",
    "    # Print the unique groups of 5 missing columns\n",
    "    if verbose==True:\n",
    "        print('\\nmissing values groups:')\n",
    "        for i, group in enumerate(sorted_unique_missing_column_groups, start=1):\n",
    "            print(f\"Group {i} of {len(group)} missing columns: {group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class remove_NAs_col(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=None,verbose=False):        \n",
    "        self.threshold = threshold  # Minimum non-NA values required to keep a column\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y=None):\n",
    "        printt('','In RemoveNAs Col fit',verbose=self.verbose)\n",
    "        # If threshold is set, identify columns to keep based on the threshold\n",
    "        self.columns_to_keep_,self.columns_to_remove_ = find_bad_col(X,self.threshold,self.verbose)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        printt('','In RemoveNAs Col transform',verbose=self.verbose)\n",
    "        # Drop columns not meeting the threshold requirement\n",
    "        printt(X.shape,'X.shape',verbose=self.verbose)\n",
    "        X_transformed = X.loc[:, self.columns_to_keep_]\n",
    "        printt(X_transformed.shape,'X_transformed.shape',verbose=self.verbose)        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imput_NAs_row(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, verbose=False):        \n",
    "        self.column_means_ = None\n",
    "        self.verbose = verbose\n",
    "        self.col_numeric = None\n",
    "        self.col_object = None\n",
    "        self.mean_per_Neighborhood = None\n",
    "    def fit(self, X, y=None):\n",
    "        printt('','In imput_NAs_row fit',verbose=self.verbose)\n",
    "        # Calculate mean values for each column, ignoring NA's\n",
    "        printt(X.shape,'imput_NAs_row in X.shape',verbose=self.verbose)\n",
    "        # save the mean and the mode for later imputation\n",
    "        self.mean_mode,self.col_numeric,self.col_object = calc_mean_mode(X)\n",
    "        self.mean_per_Neighborhood = calc_mean_Pef_feature(X,feature='Neighborhood')\n",
    "        print_row_nan_counts(X,verbose=self.verbose)\n",
    "        print_missingVal_groups(X,verbose=self.verbose)        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        printt('','In imput_NAs_row transform',verbose=self.verbose)\n",
    "        printt(X.shape,'X.shape',verbose=self.verbose)\n",
    "        print_row_nan_counts(X,verbose=self.verbose)\n",
    "\n",
    "        printt('','filing Garage and Bsmt',verbose=self.verbose)\n",
    "        # Replace NaN values in the specified columns for rows where 'TotalBsmtSF' is equal to 0 with 'NotExist'\n",
    "        basement_list = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n",
    "        Garage_list = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "        X.loc[X['TotalBsmtSF'] == 0, basement_list] = X.loc[X['TotalBsmtSF'] == 0, basement_list].fillna('NotExist')\n",
    "        X.loc[X['GarageArea'] == 0, Garage_list] = X.loc[X['GarageArea'] == 0, Garage_list].fillna('NotExist')\n",
    "        print_row_nan_counts(X,verbose=self.verbose)\n",
    "        # special imputation\n",
    "        printt('','special imputation',verbose=self.verbose)\n",
    "        X['GarageYrBlt'].fillna(X['YearBuilt'], inplace=True)        \n",
    "        X['GarageArea'].fillna(0,inplace=True)\n",
    "        X['GarageCars'].fillna(0,inplace=True)\n",
    "        X['BsmtFinType2'].fillna('NotExist', inplace=True)\n",
    "        X['BsmtExposure'].fillna('NotExist', inplace=True)\n",
    "        print_row_nan_counts(X,verbose=self.verbose)\n",
    "\n",
    "        printt('','imput_mean_mode',verbose=self.verbose)\n",
    "\n",
    "        imput_mean_per_Neighborhood_flag = False\n",
    "        imput_mean_mode_flag = True         \n",
    "        imput_0_Notexist = False         \n",
    "\n",
    "        if imput_mean_per_Neighborhood_flag==True:\n",
    "            X = imput_mean_per_Neighborhood(X,self.mean_per_Neighborhood,self.mean_mode,feature='Neighborhood')\n",
    "        if imput_mean_mode_flag == True:          \n",
    "            X = imput_mean_mode(X,self.mean_mode)\n",
    "        if imput_0_Notexist == True:          \n",
    "            X[self.col_numeric] = X[self.col_numeric].fillna(0)\n",
    "            X[self.col_object] = X[self.col_object].fillna('NotExist')        \n",
    "        print_row_nan_counts(X,verbose=self.verbose)\n",
    "        #printt(self.col_object)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_qual_categoric(X,y=None,verbose=False):\n",
    "# Assuming X is your DataFrame\n",
    "\n",
    "    category_sets = [\n",
    "        set(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NotExist']),\n",
    "        set(['Gd', 'Av', 'Mn', 'No', 'NotExist']),\n",
    "        set(['GLQ','ALQ','BLQ','Rec','LwQ','Unf','NotExist']),\n",
    "        set(['Fin','RFn','Unf','NotExist']),\n",
    "        set(['GdPrv','MnPrv','GdWo','MnWw','NotExist']),\n",
    "    ]\n",
    "    titles = ['quality_mapping', 'access_mapping', 'basement_mapping', 'garage_mapping', 'fence_mapping']\n",
    "    \n",
    "    # Mappings\n",
    "    quality_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NotExist': 0}\n",
    "    access_mapping = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NotExist': 0}\n",
    "    basement_mapping = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NotExist': 0}\n",
    "    garage_mapping = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
    "    fence_mapping = {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'NotExist': 0}\n",
    "    \n",
    "    # Mapping from titles to actual mappings\n",
    "    mapping_dict = {\n",
    "        'quality_mapping': quality_mapping,\n",
    "        'access_mapping': access_mapping,\n",
    "        'basement_mapping': basement_mapping,\n",
    "        'garage_mapping': garage_mapping,\n",
    "        'fence_mapping': fence_mapping,\n",
    "    }\n",
    "    \n",
    "    # Select columns of object type\n",
    "    col_object = X.select_dtypes(include=['O']).columns.tolist()\n",
    "    \n",
    "    matching_categories = {}\n",
    "    for col in col_object:\n",
    "        vals = set(X[col].unique())\n",
    "        # Check which category set vals belongs to\n",
    "        for index, category_set in enumerate(category_sets):\n",
    "            if vals.issubset(category_set):  # Check if all elements of vals are in the category_set\n",
    "                matching_categories[col] = titles[index]                \n",
    "                break  # Exit the loop if a matching set is found\n",
    "\n",
    "    # Apply the matched mappings to the columns\n",
    "    X_ = X.copy()\n",
    "    for col, title in matching_categories.items():\n",
    "        if title in mapping_dict:\n",
    "            X_[col] = X[col].map(mapping_dict[title])\n",
    "\n",
    "    if verbose==True:\n",
    "        printt(len(matching_categories),'matching_categories')\n",
    "        print(list(matching_categories.keys()))\n",
    "        for col, title in matching_categories.items():\n",
    "            if y is not None and not y.empty:\n",
    "                categoric_analysis(X[[col]],y,True)\n",
    "            print(f\"{col}: {title} : {mapping_dict[title]}\")\n",
    "    \n",
    "    return X_\n",
    "\n",
    "#replace_qual_categoric()\n",
    "def print_features(X,y,col_list=None): \n",
    "    if col_list is None:\n",
    "        col_list = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "    columns_to_keep_,columns_to_remove_ = find_bad_col(X,.15)\n",
    "    Xnew = X.loc[:, columns_to_keep_]\n",
    "    print(Xnew.shape)\n",
    "    imp = imput_NAs_row()\n",
    "    imp.fit(Xnew)\n",
    "    Xnew = imp.transform(Xnew)\n",
    "    print(Xnew.shape)\n",
    "    X_ = replace_qual_categoric(Xnew[col_list],y,verbose=True)\n",
    "    Xnew.shape,X_.shape\n",
    "\n",
    "if 0:\n",
    "    print_features(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handle_categoric(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,categortic_Config_params,verbose=False,col_to_map=None):        \n",
    "        self.col_numeric = None\n",
    "        self.verbose = verbose\n",
    "        self.col_object = None\n",
    "        self.col_to_map = col_to_map\n",
    "        self.col_to_map_num = ['MoSold','MSSubClass']\n",
    "        self.categoric_map_num = None\n",
    "        self.categortic_Config_params = categortic_Config_params\n",
    "        self.ymean = None\n",
    "    def fit(self, X, y=None):\n",
    "        printt('','In categoric fit',verbose=self.verbose)\n",
    "        self.col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        self.col_object = X.select_dtypes(include=['O']).columns.tolist()\n",
    "        #col_to_map = manual_feature_importance['high']\n",
    "        col_to_map = self.col_object\n",
    "        self.categoric_map  = categoric_to_numeric_fit(X,y,self.categortic_Config_params,cols=col_to_map,JustCategoric=True,verbose=self.verbose)\n",
    "        self.categoric_map_num = categoric_to_numeric_fit(X,y,self.categortic_Config_params,cols=self.col_to_map_num,JustCategoric=False,verbose=self.verbose)\n",
    "        self.ymean = np.mean(y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        printt(f\"drop_categoric: {self.categortic_Config_params['drop_categoric']}\",'',verbose=self.verbose)\n",
    "        # for now remove all categoric TODO: improve this\n",
    "        printt('','In categoric transform',verbose=self.verbose)\n",
    "        printt(X.shape,'X.shape',verbose=self.verbose)\n",
    "\n",
    "        if self.categortic_Config_params['drop_categoric']=='KeepJustOrdered' :\n",
    "            X = replace_qual_categoric(X,verbose=self.verbose)\n",
    "            col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "            left_objects = len(X.select_dtypes(include=['O']).columns.tolist())\n",
    "            printt('',f'number of num feature befor {len(self.col_numeric)}, added {len(col_numeric) - len(self.col_numeric)}, left_objects: {left_objects}',verbose=self.verbose)\n",
    "            X = X.loc[:, col_numeric]\n",
    "\n",
    "        if self.categortic_Config_params['drop_categoric'] == 'TransformAll':       \n",
    "            printt('','I am in Transform Categoric',verbose=self.verbose)\n",
    "            X = categoric_to_numeric_transform(X,self.categoric_map,verbose=self.verbose)\n",
    "            X = categoric_to_numeric_transform(X,self.categoric_map_num,verbose=self.verbose)\n",
    "            X = imput_mean(X,self.ymean)\n",
    "            #display(X)\n",
    "            col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "            X = X.loc[:, col_numeric]            \n",
    "            \n",
    "        if self.categortic_Config_params['drop_categoric'] =='DropAll':\n",
    "            col_numeric = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "            X = X.loc[:, col_numeric]\n",
    "\n",
    "        #printt(X.shape,'X.shape')\n",
    "        #printt(len(X.select_dtypes(include=['O']).columns.tolist()),'length Object')\n",
    "        #printt(X.select_dtypes(include=['O']).columns.tolist())\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,PefrormFeatureEngineering=True,verbose=False):        \n",
    "        self.verbose = verbose\n",
    "        self.PefrormFeatureEngineering = PefrormFeatureEngineering\n",
    "    def fit(self, X, y=None):\n",
    "        return self    \n",
    "    def transform(self, X):\n",
    "        if self.PefrormFeatureEngineering==True:\n",
    "            printt(X.shape,'shape befor FeatureEngineering',self.verbose)\n",
    "            X['YrBltAndRemod']=X['YearBuilt']+X['YearRemodAdd']\n",
    "            X['TotalSF']=X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "            \n",
    "            X['Total_sqr_footage'] = (X['BsmtFinSF1'] + X['BsmtFinSF2'] +\n",
    "                                             X['1stFlrSF'] + X['2ndFlrSF'])\n",
    "            \n",
    "            X['Total_Bathrooms'] = (X['FullBath'] + (0.5 * X['HalfBath']) +\n",
    "                                           X['BsmtFullBath'] + (0.5 * X['BsmtHalfBath']))\n",
    "            \n",
    "            X['Total_porch_sf'] = (X['OpenPorchSF'] + X['3SsnPorch'] +\n",
    "                                          X['EnclosedPorch'] + X['ScreenPorch'] +\n",
    "                                          X['WoodDeckSF'])\n",
    "            X['haspool'] = X['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "            X['has2ndfloor'] = X['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "            X['hasgarage'] = X['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "            X['hasbsmt'] = X['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "            X['hasfireplace'] = X['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "            printt(X.shape,'shape After FeatureEngineering',self.verbose)            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimReduction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,verbose=False, manual_columns_to_keep=None):        \n",
    "        self.verbose = verbose\n",
    "        self.calc_columns_to_keep_ = None\n",
    "        self.manual_columns_to_keep = manual_columns_to_keep\n",
    "    def fit(self, X, y=None):\n",
    "        df_temp = X.copy()  # Make a copy of the features DataFrame\n",
    "        df_temp['target'] = y  # Add the target variable as a new column named 'target'    \n",
    "        correlation_matrix = df_temp.corr()\n",
    "        target_correlation = correlation_matrix['target'].drop('target', axis=0)\n",
    "        target_correlation_abs = target_correlation.abs()\n",
    "        #self.keep_col = target_correlation_sorted>0.0\n",
    "        #pd.set_option('display.max_rows', None)\n",
    "        #print(target_correlation_abs.sort_values(ascending=False))\n",
    "        #pd.reset_option('display.max_rows')\n",
    "        self.calc_columns_to_keep_ = target_correlation_abs>0.01\n",
    "        return self    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.loc[:, self.calc_columns_to_keep_]\n",
    "        printt(f'{X_transformed.shape[1]}/{X.shape[1]}','keep only high correlated featurs',self.verbose)\n",
    "        if self.manual_columns_to_keep:\n",
    "            X_transformed = X_transformed.filter(self.manual_columns_to_keep, axis=1)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "categortic_Config_params = dict()\n",
    "categortic_Config_params['MinRatioPerGroup'] = 2\n",
    "categortic_Config_params['replaceby'] = 'ymean' #'ymean', 'group_nember'\n",
    "#categortic_Config_params['categoric_to_replace'] ='just_high' # 'All','from_low_to_high','from_med_to_high','just_high'\n",
    "categortic_Config_params['drop_categoric'] = 'TransformAll' #'KeepAll','KeepJustOrdered','TransformAll','DropAll', KeepAll is the best option\n",
    "\n",
    "Config_params = dict()\n",
    "Config_params['PefrormFeatureEngineering'] = True\n",
    "Config_params['nan_counts_threshold'] = .15\n",
    "Config_params['filter_out_HighNA'] = 1\n",
    "Config_params[\"model\"]='CatBoost' #'DecisionTree','CatBoost', CatBoost is the best option\n",
    "Config_params[\"params_tuning\"]='default_params'  #'overfit_params','underfit_params','fit_params','default_params'\n",
    "Config_params[\"a\"]=1  #'overfit_params','underfit_params','fit_params','default_params'\n",
    "Config_params[\"take_log_target\"] = 0 # 0,1  . 1 is the best option\n",
    "Config_params[\"verbose\"]=False # False,True\n",
    "Config_params[\"categortic_Config_params\"] = categortic_Config_params\n",
    "Config_params_default = Config_params.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and return a pipeline based on the configuration\n",
    "def create_pipeline(Config_params):\n",
    "    verbose = Config_params[\"verbose\"]\n",
    "    categortic_Config_params = Config_params[\"categortic_Config_params\"]\n",
    "    printt(Config_params['model'],verbose = verbose)\n",
    "    # Dynamically select the model based on Config_params\n",
    "    printt(Config_params['model'],'Model',verbose=verbose)\n",
    "    do_robust = False\n",
    "    if Config_params['model'] == 'LinearRegression':\n",
    "        model = LinearRegression()\n",
    "        do_robust = True\n",
    "    if Config_params['model'] == 'Lasso':\n",
    "        model = Lasso()\n",
    "        do_robust = True\n",
    "    if Config_params['model'] == 'DecisionTree':\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "    elif Config_params['model'] == 'CatBoost':        #\n",
    "        if categortic_Config_params['drop_categoric'] == 'KeepAll':\n",
    "            cat_features = ['MSSubClass','YrSold','MSZoning', 'Street', 'LotShape', 'LandContour',\n",
    "                               'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
    "                               'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "                               'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n",
    "                               'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                               'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                               'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    "                               'Functional', 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "                               'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
    "        else:\n",
    "            cat_features = None\n",
    "        a =  Config_params['a']                 \n",
    "        overfit_params = {'iterations': 1000-100*a,'learning_rate': 0.04-0.01*a,'depth': 6-1*a,'l2_leaf_reg': 5 + 2*a}\n",
    "        underfit_params = {'iterations': 600,'learning_rate': 0.01,'depth': 3,'l2_leaf_reg': 10}        \n",
    "        good_fit_params = {'iterations': 800,'learning_rate': 0.02,'depth': 4,'l2_leaf_reg': 6}\n",
    "        common_fit_params={'silent': True,'cat_features': cat_features,'random_seed': 42}\n",
    " \n",
    "        if Config_params['params_tuning']=='overfit_params':\n",
    "            model = CatBoostRegressor(**{**overfit_params, **common_fit_params})\n",
    "        elif Config_params['params_tuning']=='underfit_params': \n",
    "            model = CatBoostRegressor(**{**underfit_params, **common_fit_params})\n",
    "        elif Config_params['params_tuning']=='fit_params': \n",
    "            model = CatBoostRegressor(**{**good_fit_params, **common_fit_params})            \n",
    "        elif Config_params['params_tuning']=='default_params':             \n",
    "             model = CatBoostRegressor(**common_fit_params)\n",
    "        params = {'silent': True,'learning_rate': 0.05262860621501329, 'depth': 5, 'subsample': 0.25142747620081446, 'colsample_bylevel': 0.9045398097461379, 'min_data_in_leaf': 6, 'n_estimators': 774}\n",
    "        model = CatBoostRegressor(**params)\n",
    "    if (Config_params['model'] == 'CatBoost') & (categortic_Config_params['drop_categoric'] == 'KeepAll'):\n",
    "        pipeline = Pipeline([\n",
    "            ('drop_ID', drop_ID(verbose=verbose)),\n",
    "            ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "            ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "            ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "            ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "            ('reg', model)  # Use the dynamically selected model\n",
    "        ])\n",
    "    else: \n",
    "        if do_robust:\n",
    "            pipeline = Pipeline([\n",
    "                ('drop_ID', drop_ID(verbose=verbose)),\n",
    "                ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "                ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "                ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "                ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "                ('DimReduction', DimReduction(verbose=verbose)),\n",
    "                ('robust_scaler', RobustScaler()),\n",
    "                ('reg', model)  # Use the dynamically selected model\n",
    "            ]) \n",
    "        else:\n",
    "            pipeline = Pipeline([\n",
    "                ('drop_ID', drop_ID(verbose=verbose)),\n",
    "                ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "                ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "                ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "                ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "                ('DimReduction', DimReduction(verbose=verbose)),\n",
    "                #('robust_scaler', RobustScaler()),\n",
    "                ('reg', model)  # Use the dynamically selected model\n",
    "            ])\n",
    "\n",
    "    \n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross val model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "def DecisionTreeCV(X,y,title,use_cv_rmse=False, x_t=None,y_t=None):\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'DecisionTree'\n",
    "    Config_params1[\"drop_categoric\"] = 'TransformAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'TransformAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    pipeline1 = create_pipeline(Config_params1)\n",
    "    y_pred = run_pipe(pipeline1, X, y,title,use_cv_rmse, x_t,y_t)\n",
    "    return y_pred\n",
    "\n",
    "def LinearModelCV(X,y,title,use_cv_rmse=False, x_t=None,y_t=None):\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'LinearRegression'\n",
    "    Config_params1[\"drop_categoric\"] = 'TransformAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'TransformAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    pipeline1 = create_pipeline(Config_params1)\n",
    "    y_pred = run_pipe(pipeline1, X, y,title,use_cv_rmse, x_t,y_t)\n",
    "    return y_pred\n",
    "\n",
    "def LinearModel():\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'Lasso'\n",
    "    Config_params1[\"drop_categoric\"] = 'TransformAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'TransformAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    return create_pipeline(Config_params1)\n",
    "    \n",
    "def LassoModel():\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'Lasso'\n",
    "    Config_params1[\"drop_categoric\"] = 'TransformAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'TransformAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    return create_pipeline(Config_params1)\n",
    "\n",
    "def RidgeModel():\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'Lasso'\n",
    "    Config_params1[\"drop_categoric\"] = 'TransformAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'TransformAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    return create_pipeline(Config_params1)\n",
    "    \n",
    "def CatTransllModelCV(X,y,title,use_cv_rmse=False, x_t=None,y_t=None,params_tuning='default_params'):\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'CatBoost'\n",
    "    Config_params1[\"params_tuning\"]=params_tuning\n",
    "    Config_params1[\"drop_categoric\"] = 'TransformAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'TransformAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    pipeline1 = create_pipeline(Config_params1)\n",
    "    y_pred = run_pipe(pipeline1, X, y,title,use_cv_rmse, x_t,y_t)\n",
    "    #print_prarams(pipeline1)\n",
    "    return y_pred\n",
    "    \n",
    "def CatKeepAllModelCV(X,y,title,use_cv_rmse=False, x_t=None,y_t=None):\n",
    "    Config_params1 = Config_params\n",
    "    Config_params1[\"model\"] = 'CatBoost'\n",
    "    Config_params1[\"drop_categoric\"] = 'KeepAll'\n",
    "    categortic_Config_params[\"drop_categoric\"] = 'KeepAll'\n",
    "    Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "    pipeline1 = create_pipeline(Config_params1)\n",
    "    y_pred = run_pipe(pipeline1, X, y,title,use_cv_rmse, x_t,y_t)\n",
    "    return y_pred\n",
    "\n",
    "def run_pipe(pipeline, X, y,title,use_cv_rmse=False, x_t=None,y_t=None):\n",
    "    if use_cv_rmse==True:\n",
    "        rms_log = cv_rmse(pipeline, X, y)\n",
    "        print(f\"LogRMS with CV {title} : {rms_log.mean():.4f} ({rms_log.std():.4f})\")\n",
    "        return None\n",
    "    else:\n",
    "        pipeline.fit(X,y)\n",
    "        y_pred = pipeline.predict(x_t)                \n",
    "        if y_t is not None:\n",
    "            rms_log = np.sqrt(mean_squared_error(y_t, y_pred))        \n",
    "            print(f\"logRMS {title} = {rms_log:.5f}\")\n",
    "        return y_pred\n",
    "\n",
    "def print_prarams(pipeline):\n",
    "    # Retrieve the actual parameter values used\n",
    "    catboost_model = pipeline.named_steps['reg']\n",
    "    actual_params = catboost_model.get_all_params()\n",
    "    actual_iterations = actual_params['iterations']\n",
    "    actual_learning_rate = actual_params['learning_rate']\n",
    "    actual_depth = actual_params['depth']\n",
    "    actual_l2_leaf_reg = actual_params['l2_leaf_reg']\n",
    "\n",
    "    \n",
    "    print(f\"Iterations: {actual_iterations}\")\n",
    "    print(f\"Learning Rate: {actual_learning_rate}\")\n",
    "    print(f\"Depth: {actual_depth}\")\n",
    "    print(f\"L2 Leaf Reg: {actual_l2_leaf_reg}\")\n",
    "\n",
    "use_cv_rmse=True\n",
    "if use_cv_rmse==False:\n",
    "    #'overfit_params','overfit_params','fit_params','default_params'\n",
    "    print('startModels')\n",
    "    y_pred_cat = CatTransllModelCV(X_train,y_train,'CatTransll_test',use_cv_rmse,X_validation,y_validation)\n",
    "    y_pred_cat = CatTransllModelCV(X_train,y_train,'CatTransll_train',use_cv_rmse,X_train,y_train)\n",
    "    print('')    \n",
    "    y_pred_dt = DecisionTreeCV(X_train,y_train,'DecisionTreeCV',use_cv_rmse,X_validation,y_validation)\n",
    "    y_pred_lr = LinearModelCV(X_train,y_train,'LinearModel',use_cv_rmse,X_validation,y_validation)\n",
    "    y_pred_cat = CatTransllModelCV(X_train,y_train,'CatTransll',use_cv_rmse,X_validation,y_validation)\n",
    "    y_pred_catcat = CatKeepAllModelCV(X_train,y_train,'CatKeepAll',use_cv_rmse,X_validation,y_validation)\n",
    "    y_pred_comb = (y_pred_lr + y_pred_cat + y_pred_catcat)/3\n",
    "    rms_log = np.sqrt(mean_squared_error(y_validation, y_pred_comb))        \n",
    "    print(f\"logRMS y_pred_comp = {rms_log:.5f}\")\n",
    "\n",
    "else:\n",
    "    print(\":)\")\n",
    "    #DecisionTreeCV(X,y,'DecisionTreeCV',use_cv_rmse)\n",
    "    #LinearModelCV(X,y,'LinearModel',use_cv_rmse)\n",
    "    #CatTransllModelCV(X,y,'CatTransll',use_cv_rmse)\n",
    "    #CatKeepAllModelCV(X,y,'CatKeepAll',use_cv_rmse)\n",
    "\n",
    "#LogRMS with CV DecisionTreeCV : 0.2081 (0.0225)\n",
    "#LogRMS with CV LinearModel : 0.1518 (0.0307)\n",
    "#LogRMS with CV CatTransll : 0.1205 (0.0121)\n",
    "#LogRMS with CV CatKeepAll : 0.1235 (0.0151)\n",
    "lasso_pipeline = LassoModel()\n",
    "linear_pipeline = LinearModel()\n",
    "ridge_pipeline = RidgeModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finish line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model_lr = LinearRegression()\n",
    "    model_dt = DecisionTreeRegressor(random_state=42)\n",
    "    model_cat = CatBoostRegressor(random_state=42, verbose=0)  # Adjust verbosity for CatBoost\n",
    "    \n",
    "    pipeline = create_pipeline(Config_params_default)\n",
    "    XX = pipeline.named_steps['drop_ID'].fit_transform(X_train)\n",
    "    XX = pipeline.named_steps['remove_nas_col'].fit_transform(XX)\n",
    "    XX = pipeline.named_steps['imput_nas_row'].fit_transform(XX)\n",
    "    XX = pipeline.named_steps['handle_categoric'].fit_transform(XX,y=y_train)\n",
    "    XX = pipeline.named_steps['robust_scaler'].fit_transform(XX)\n",
    "    model_lr.fit(XX,y=y_train)\n",
    "    model_dt.fit(XX,y=y_train)\n",
    "    model_cat.fit(XX,y=y_train)\n",
    "    #pipeline.named_steps['reg'].fit(XX,y=y_train)\n",
    "    \n",
    "    \n",
    "    XX = pipeline.named_steps['drop_ID'].transform(X_validation)\n",
    "    XX = pipeline.named_steps['remove_nas_col'].transform(XX)\n",
    "    XX = pipeline.named_steps['imput_nas_row'].transform(XX)\n",
    "    XX = pipeline.named_steps['handle_categoric'].transform(XX)\n",
    "    XX = pipeline.named_steps['robust_scaler'].transform(XX)\n",
    "    #y_pred = pipeline.named_steps['reg'].predict(XX)\n",
    "    y_lr = model_lr.predict(XX)\n",
    "    y_dt = model_dt.predict(XX)\n",
    "    y_cat = model_cat.predict(XX)\n",
    "\n",
    "    def CatKeepAllModel(X,y,x_test):\n",
    "        Config_params1 = Config_params\n",
    "        Config_params1[\"model\"] = 'CatBoost'\n",
    "        Config_params1[\"drop_categoric\"] = 'KeepAll'\n",
    "        Config_params1[\"categortic_Config_params\"] = {**categortic_Config_params, \"drop_categoric\": 'KeepAll'}\n",
    "        pipeline = create_pipeline(Config_params1)\n",
    "        pipeline.fit(X,y)\n",
    "        y_cat_keepAll = pipeline.predict(x_test)\n",
    "        return y_cat_keepAll\n",
    "    \n",
    "    def CombModel(X,y,x_test):\n",
    "        Config_params1 = Config_params\n",
    "        Config_params1[\"model\"] = 'CatBoost'\n",
    "        pipeline = create_pipeline(Config_params)\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        y_cat = pipeline.predict(x_test)\n",
    "        Config_params1[\"model\"] = 'DecisionTree'\n",
    "        pipeline = create_pipeline(Config_params)\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        y_dt = pipeline.predict(x_test)  \n",
    "        y_comb = y_cat.copy()\n",
    "        y_comb[(y_dt<10.9) | (y_dt>13)] = y_dt[(y_dt<10.9) | (y_dt>13)]\n",
    "        return y_comb\n",
    "    \n",
    "    \n",
    "    rms_log = np.sqrt(mean_squared_error(y_validation, y_dt))        \n",
    "    print(f\"logRMS y_dt = {rms_log:.5f}\")\n",
    "    rms_log = np.sqrt(mean_squared_error(y_validation, y_lr))        \n",
    "    print(f\"logRMS y_lr = {rms_log:.5f}\")\n",
    "    rms_log = np.sqrt(mean_squared_error(y_validation, y_cat))        \n",
    "    print(f\"logRMS y_cat = {rms_log:.5f}\")\n",
    "    \n",
    "    y_comb = CombModel(X_train,y_train,X_validation)\n",
    "    rms_log = np.sqrt(mean_squared_error(y_validation, y_comb))        \n",
    "    print(f\"logRMS y_comb = {rms_log:.5f}\")\n",
    "    \n",
    "    y_cat_keepAll = CatKeepAllModel(X_train,y_train,X_validation)\n",
    "    rms_log = np.sqrt(mean_squared_error(y_validation, y_cat_keepAll))        \n",
    "    print(f\"logRMS y_cat_keepAll = {rms_log:.5f}\")\n",
    "    \n",
    "    plot_pred(y_validation, y_comb,True) \n",
    "    plot_pred(y_validation, y_cat,True) \n",
    "    plot_pred(y_validation, y_lr,True)     \n",
    "    plot_pred(y_validation, y_dt,True)     \n",
    "\n",
    "    \n",
    "#XX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter:\n",
    "# check best MinRatioPerGroupV with CatBoost\n",
    "if 0:\n",
    "    MinRatioPerGroupV = [0.01,1,2,4,6,10,15,20,50] #'KeepAll','KeepJustOrdered','DropAll','TransformAll'\n",
    "    modelV = ['LinearRegression','CatBoost'],\n",
    "    for model in modelV:\n",
    "        for MinRatioPerGroup in MinRatioPerGroupV:\n",
    "            # update config\n",
    "            Config_params1 = Config_params\n",
    "            Config_params1['Model'] = model\n",
    "            categortic_Config_params['MinRatioPerGroup'] = MinRatioPerGroup\n",
    "            Config_params1[\"categortic_Config_params\"] = categortic_Config_params\n",
    "            pipeline1 = create_pipeline(Config_params1)\n",
    "            #pipeline1.fit(X_train,y_train)\n",
    "            #y_cat = pipeline1.predict(X_validation)\n",
    "            rms_log = cv_rmse(pipeline1, X, y)\n",
    "            print(f\"LogRMS with CV MinRatioPerGroup={MinRatioPerGroup}: {rms_log.mean():.4f} ({rms_log.std():.4f})\")\n",
    "            #print(\"LogRMS with CV MinRatioPerGroup={}: {:.4f} ({:.4f})\\n\".format(MinRatioPerGroup,rms_log.mean(), rms_log.std()))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created for model: CatBoost, drop_categoric: TransformAll\n",
      "Start fit\n",
      "Start predict\n",
      "logRMS = 0.13038\n",
      "LogRMS with CV: 0.1154 (0.0202)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterate over all combinations\n",
    "models = ['LinearRegression','CatBoost'] #['DecisionTree', 'CatBoost']\n",
    "models = ['CatBoost'] #['DecisionTree', 'CatBoost']\n",
    "\n",
    "drop_categoric_options = ['TransformAll'] #'KeepAll','KeepJustOrdered','DropAll','TransformAll'\n",
    "\n",
    "i=0\n",
    "if 1:\n",
    "    pipelines = {}\n",
    "    for model in models:\n",
    "        for drop_categoric in drop_categoric_options:\n",
    "                # update config\n",
    "                Config_params1 = Config_params\n",
    "                Config_params1[\"model\"] = model\n",
    "                Config_params1[\"drop_categoric\"] = drop_categoric\n",
    "                Config_params1[\"categortic_Config_params\"] = {**categortic_Config_params, \"drop_categoric\": drop_categoric}\n",
    "    \n",
    "                # create pipe\n",
    "                print(f\"Pipeline created for model: {model}, drop_categoric: {drop_categoric}\")\n",
    "                pipeline = create_pipeline(Config_params1)\n",
    "                print('Start fit')\n",
    "                pipeline.fit(X_train,y_train)\n",
    "                print('Start predict')\n",
    "                y_pred = pipeline.predict(X_validation)\n",
    "        \n",
    "                # check errors \n",
    "                mask = y_validation > 0\n",
    "                rms_log = np.sqrt(mean_squared_error(y_validation[mask], y_pred[mask]))        \n",
    "                print(f\"logRMS = {rms_log:.5f}\")\n",
    "                pipelines[i] = pipeline\n",
    "                i=i+1     \n",
    "            \n",
    "\n",
    "# create pipe\n",
    "# verbose=0\n",
    "# params = {'learning_rate': 0.05262860621501329, 'depth': 5, 'subsample': 0.25142747620081446, 'colsample_bylevel': 0.9045398097461379, 'min_data_in_leaf': 6, 'n_estimators': 774}\n",
    "# pipeline = Pipeline([\n",
    "#     ('drop_ID', drop_ID(verbose=verbose)),\n",
    "#     ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "#     ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "#     ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "#     ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "#     ('DimReduction', DimReduction(verbose=verbose)),\n",
    "#     ('reg', CatBoostRegressor(**params, silent=True))  # Use the dynamically selected model\n",
    "# ])  \n",
    "rms_log = cv_rmse(pipeline, X, y)\n",
    "print(\"LogRMS with CV: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "plot_pred(y_validation, y_pred,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    TSNE_model = TSNE(n_components=2, random_state=0, perplexity=50)\n",
    "    List = ['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','LotShape','Neighborhood','ExterQual','Foundation','BsmtQual','HeatingQC','KitchenQual','GarageType','GarageFinish']\n",
    "    #List = ['GrLivArea','GarageArea','TotalBsmtSF']\n",
    "    \n",
    "    tsne = TSNE_model.fit_transform(XX[List])\n",
    "    if 1:\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(XX[List])\n",
    "        XX_pca = pca.transform(XX[List])\n",
    "        kmeans = KMeans(n_clusters=5)\n",
    "        kmeans.fit(XX[List])\n",
    "        fr = pd.DataFrame({'tsne1': tsne[:,0], 'tsne2': tsne[:, 1], 'cluster': kmeans.labels_})\n",
    "        print(np.sum(pca.explained_variance_ratio_))\n",
    "        sns.lmplot(data=fr, x='tsne1', y='tsne2', hue='cluster', fit_reg=False)\n",
    "    \n",
    "    fr = pd.DataFrame({'tsne1': tsne[:,0], 'tsne2': tsne[:, 1], 'cluster': y_train<11.5})\n",
    "    sns.lmplot(data=fr, x='tsne1', y='tsne2', hue='cluster', fit_reg=False)\n",
    "    \n",
    "    unique_labels = np.unique(kmeans.labels_)\n",
    "    means = {label: y_train[kmeans.labels_ == label].mean() for label in unique_labels}\n",
    "    std = {label: y_train[kmeans.labels_ == label].std() for label in unique_labels}\n",
    "    for label in unique_labels:\n",
    "        print(f'Mean of cluster {label}: {means[label]}, {std[label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;drop_ID&#x27;, drop_ID()),\n",
       "                (&#x27;remove_nas_col&#x27;, remove_NAs_col(threshold=0.15)),\n",
       "                (&#x27;imput_nas_row&#x27;, imput_NAs_row()),\n",
       "                (&#x27;FeatureEngineering&#x27;, FeatureEngineering()),\n",
       "                (&#x27;handle_categoric&#x27;,\n",
       "                 handle_categoric(categortic_Config_params={&#x27;MinRatioPerGroup&#x27;: 2,\n",
       "                                                            &#x27;drop_categoric&#x27;: &#x27;TransformAll&#x27;,\n",
       "                                                            &#x27;replaceby&#x27;: &#x27;ymean&#x27;})),\n",
       "                (&#x27;DimReduction&#x27;, DimReduction()),\n",
       "                (&#x27;reg&#x27;,\n",
       "                 &lt;catboost.core.CatBoostRegressor object at 0x000002B1CAEDC5B0&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;drop_ID&#x27;, drop_ID()),\n",
       "                (&#x27;remove_nas_col&#x27;, remove_NAs_col(threshold=0.15)),\n",
       "                (&#x27;imput_nas_row&#x27;, imput_NAs_row()),\n",
       "                (&#x27;FeatureEngineering&#x27;, FeatureEngineering()),\n",
       "                (&#x27;handle_categoric&#x27;,\n",
       "                 handle_categoric(categortic_Config_params={&#x27;MinRatioPerGroup&#x27;: 2,\n",
       "                                                            &#x27;drop_categoric&#x27;: &#x27;TransformAll&#x27;,\n",
       "                                                            &#x27;replaceby&#x27;: &#x27;ymean&#x27;})),\n",
       "                (&#x27;DimReduction&#x27;, DimReduction()),\n",
       "                (&#x27;reg&#x27;,\n",
       "                 &lt;catboost.core.CatBoostRegressor object at 0x000002B1CAEDC5B0&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_ID</label><div class=\"sk-toggleable__content\"><pre>drop_ID()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remove_NAs_col</label><div class=\"sk-toggleable__content\"><pre>remove_NAs_col(threshold=0.15)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imput_NAs_row</label><div class=\"sk-toggleable__content\"><pre>imput_NAs_row()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureEngineering</label><div class=\"sk-toggleable__content\"><pre>FeatureEngineering()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">handle_categoric</label><div class=\"sk-toggleable__content\"><pre>handle_categoric(categortic_Config_params={&#x27;MinRatioPerGroup&#x27;: 2,\n",
       "                                           &#x27;drop_categoric&#x27;: &#x27;TransformAll&#x27;,\n",
       "                                           &#x27;replaceby&#x27;: &#x27;ymean&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DimReduction</label><div class=\"sk-toggleable__content\"><pre>DimReduction()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x000002B1CAEDC5B0&gt;</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('drop_ID', drop_ID()),\n",
       "                ('remove_nas_col', remove_NAs_col(threshold=0.15)),\n",
       "                ('imput_nas_row', imput_NAs_row()),\n",
       "                ('FeatureEngineering', FeatureEngineering()),\n",
       "                ('handle_categoric',\n",
       "                 handle_categoric(categortic_Config_params={'MinRatioPerGroup': 2,\n",
       "                                                            'drop_categoric': 'TransformAll',\n",
       "                                                            'replaceby': 'ymean'})),\n",
       "                ('DimReduction', DimReduction()),\n",
       "                ('reg',\n",
       "                 <catboost.core.CatBoostRegressor object at 0x000002B1CAEDC5B0>)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([134, 181, 197], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_low_prices(y,threshold):\n",
    "    values = y[y <= threshold]\n",
    "    indexes = np.where(y <= threshold)[0]\n",
    "    #print(y.iloc[indexes])\n",
    "    #print(np.exp(values))\n",
    "    #print(index)\n",
    "    return indexes\n",
    "find_low_prices(y_validation,threshold=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "top_names\n",
      "['TotalSF' 'OverallQual' 'Total_sqr_footage' 'Neighborhood' 'GrLivArea'\n",
      " 'GarageArea' 'OverallCond' 'LotArea']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Post_Proccessing(pipeline):\n",
    "    model = pipeline.named_steps['reg']\n",
    "    \n",
    "    # Step 3: Get Feature Importances\n",
    "    feature_importances = model.get_feature_importance()\n",
    "    feature_names = model.feature_names_\n",
    "    sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "    \n",
    "    # Limit to first 8 features\n",
    "    top_indices = sorted_indices[:8]\n",
    "    top_importances = feature_importances[top_indices]\n",
    "    top_names = np.array(feature_names)[top_indices]\n",
    "\n",
    "    printt(top_names,'top_names')\n",
    "    #print_features(X,y,top_names)\n",
    "    # Plot\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.title(\"Top 8 Feature Importances\")\n",
    "    plt.barh(range(len(top_importances)), top_importances, align=\"center\")\n",
    "    plt.yticks(range(len(top_importances)), top_names)\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the feature with the highest importance on top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def Post_Proccessing_shap(pipeline):\n",
    "    model = pipeline.named_steps['reg']\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    # Summarize the effects of all the features\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n",
    "Post_Proccessing(pipelines[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class keep_columns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_keep):        \n",
    "        self.columns_to_keep = columns_to_keep\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "categortic_Config_params['drop_categoric'] = 'TransformAll'\n",
    "#categortic_Config_params['drop_categoric'] = 'KeepAll'\n",
    "general_pipeline = Pipeline([\n",
    "    ('drop_ID', drop_ID(verbose=Config_params['verbose'])),\n",
    "    ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "    ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "    ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose))\n",
    "])\n",
    "_X = general_pipeline.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows  80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "...          ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0      2    2008        WD         Normal  \n",
       "1            NaN       0      5    2007        WD         Normal  \n",
       "2            NaN       0      9    2008        WD         Normal  \n",
       "3            NaN       0      2    2006        WD        Abnorml  \n",
       "4            NaN       0     12    2008        WD         Normal  \n",
       "...          ...     ...    ...     ...       ...            ...  \n",
       "1455         NaN       0      8    2007        WD         Normal  \n",
       "1456         NaN       0      2    2010        WD         Normal  \n",
       "1457        Shed    2500      5    2010        WD         Normal  \n",
       "1458         NaN       0      4    2010        WD         Normal  \n",
       "1459         NaN       0      6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Catboost ###\n",
    "params = {'learning_rate': 0.04623050108208682, 'depth': 5, 'subsample': 0.34619188028935577, 'colsample_bylevel': 0.9348622687578646, 'min_data_in_leaf': 3, 'n_estimators': 685}\n",
    "cat_pipeline = Pipeline([\n",
    "    ('drop_ID', drop_ID(verbose=verbose)),\n",
    "    ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "    ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "    ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "    ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "    ('DimReduction', DimReduction(verbose=verbose)),\n",
    "    ('reg', CatBoostRegressor(**params, silent=True))  # Use the dynamically selected model\n",
    "])\n",
    "\n",
    "### XGBoost ###\n",
    "params = {'learning_rate': 0.01855669447600312, 'max_depth': 3, 'subsample': 0.62999044367645, 'colsample_bytree': 0.7377662582206219, 'n_estimators': 1935, 'min_child_weight': 10, 'gamma': 0.0002617938145228569, 'scale_pos_weight': 0.584286057025207, 'reg_alpha': 0.09134864973338383}\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('drop_ID', drop_ID(verbose=verbose)),\n",
    "    ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "    ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "    ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "    ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "    ('DimReduction', DimReduction(verbose=verbose)),\n",
    "    ('reg', xgb.XGBRegressor(**params))  # Use the dynamically selected model\n",
    "])\n",
    "\n",
    "### GBR ###\n",
    "params = {'n_estimators': 2391, 'learning_rate': 0.019533617103613395, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 20, 'loss': 'absolute_error'}\n",
    "gbr_pipeline = Pipeline([\n",
    "    ('drop_ID', drop_ID(verbose=verbose)),\n",
    "    ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "    ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "    ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "    ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "    ('DimReduction', DimReduction(verbose=verbose)),\n",
    "    ('reg', GradientBoostingRegressor(**params))  # Use the dynamically selected model\n",
    "]) \n",
    "\n",
    "### LGBM ###\n",
    "params = {'num_leaves': 20, 'learning_rate': 0.001496794863104804, 'n_estimators': 9754, 'max_bin': 187, 'bagging_fraction': 0.7000772715567462, 'bagging_freq': 3, 'feature_fraction': 0.24385248059776302}\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('drop_ID', drop_ID(verbose=verbose)),\n",
    "    ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "    ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "    ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "    ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "    ('DimReduction', DimReduction(verbose=verbose)),\n",
    "    ('reg', LGBMRegressor(**params, silent=True))  # Use the dynamically selected model\n",
    "])\n",
    "\n",
    "# ### Ridge ###\n",
    "# params = {\n",
    "#     \"alpha\": trial.suggest_float(\"alpha\", 0.1, 20, log=True)\n",
    "# }\n",
    "# ridge_pipeline = Pipeline([\n",
    "#     ('drop_ID', drop_ID(verbose=verbose)),\n",
    "#     ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "#     ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "#     ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "#     ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "#     ('DimReduction', DimReduction(verbose=verbose)),\n",
    "#     ('robust_scaler', RobustScaler()),\n",
    "#     ('reg', Ridge(**params))  # Use the dynamically selected model\n",
    "# ])\n",
    "\n",
    "# ### Lasso ###\n",
    "# params = {\n",
    "#     \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 1, log=True)\n",
    "# }\n",
    "# lasso_pipeline = Pipeline([\n",
    "#     ('drop_ID', drop_ID(verbose=verbose)),\n",
    "#     ('remove_nas_col', remove_NAs_col(threshold=Config_params['nan_counts_threshold'], verbose=verbose)),\n",
    "#     ('imput_nas_row', imput_NAs_row(verbose=verbose)),\n",
    "#     ('FeatureEngineering',FeatureEngineering(PefrormFeatureEngineering=Config_params['PefrormFeatureEngineering'],verbose=verbose)),\n",
    "#     ('handle_categoric', handle_categoric(categortic_Config_params,verbose=verbose)),\n",
    "#     ('DimReduction', DimReduction(verbose=verbose)),\n",
    "#     ('robust_scaler', RobustScaler()),\n",
    "#     ('reg', Lasso(**params))  # Use the dynamically selected model\n",
    "# ])   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('cat', cat_pipeline),\n",
    "    ('xgb', xgb_pipeline),\n",
    "    ('gbr', gbr_pipeline),\n",
    "    ('lgbm', lgbm_pipeline)\n",
    "    # ('lasso', lasso),\n",
    "    # ('elasticnet', elasticnet),\n",
    "    # ('svr', svr),\n",
    "    # ('lightgbm', lightgbm),\n",
    "    # ('xgboost', xgboost),\n",
    "    # ('rf', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "]\n",
    "cat_boost = CatBoostRegressor( colsample_bylevel= 0.531075668433829, l2_leaf_reg = 5,random_state=42, verbose=int(Config_params['verbose']), learning_rate = 0.07648637470643878, depth= 5, subsample= 0.7260127449737658, min_data_in_leaf= 2, n_estimators= 730)\n",
    "#base_models = (cat_pipeline, gbr,lreg_pipeline,lasso,elasticnet,svr, lightgbm,xgboost,RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "base_models = (cat_pipeline, gbr_pipeline, lgbm_pipeline, xgb_pipeline)\n",
    "meta_learner = LinearRegression()\n",
    "stacking_regressor = StackingRegressor(estimators=models, final_estimator=meta_learner)\n",
    "# stacking_regressor = StackingCVRegressor(regressors=base_models,\n",
    "#                                 meta_regressor=meta_learner,\n",
    "#                                 use_features_in_secondary=True)\n",
    "# stacking_regressor.fit(X_train, y_train)       \n",
    "# predict_func = stacking_regressor.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.025317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3210\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.022863\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3192\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.023773\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3206\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.021032\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3185\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 12.034641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3221\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.024278\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.028652\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3204\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.025853\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3210\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.030142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3174\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.022653\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3186\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.037110\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3209\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.027505\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3384\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.021949\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3193\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.015361\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3210\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.021050\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3196\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.021041\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.033315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3177\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.018983\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3421\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.019789\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3186\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.016103\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3201\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.018235\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3193\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.013931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.029948\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3215\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.020724\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3426\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.020656\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3204\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.016936\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3164\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.021406\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3186\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.017301\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3187\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.029820\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3203\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.017822\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3376\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.026291\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3160\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.024558\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3209\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.025460\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3139\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 12.022517\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3180\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.034153\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3167\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.024767\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3311\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.029430\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3166\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.027989\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3212\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.026430\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3175\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 12.028976\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.035046\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3177\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.028707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3375\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.022117\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3155\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.020177\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3210\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.025913\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.015809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3182\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.028459\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3171\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.020228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3375\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.023871\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3160\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.022125\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3213\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.024805\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3181\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.017618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3181\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.033696\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3209\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.021113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3381\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.022437\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3208\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.020110\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.020563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.24385248059776302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24385248059776302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7000772715567462, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7000772715567462\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3193\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.021708\n"
     ]
    }
   ],
   "source": [
    "rms_log = cv_rmse(stacking_regressor, X, y)\n",
    "print(\"stacking regressor: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "#     rms_log = cv_rmse(model[1], X, y)\n",
    "#     print(f\"model : {model[0]} mean score : {rms_log.mean()} std : {rms_log.std()}\")\n",
    "# _X = X[selected_features]\n",
    "# _X = _X.drop(['MSSubClass', 'Exterior2nd', 'Exterior1st'], axis=1, errors='ignore')\n",
    "# columns_to_drop = ['GarageQual', 'Functional', 'GarageCond', 'Electrical', 'PavedDrive', \n",
    "#                    'SaleType', 'MSZoning', 'ExterQual', 'LotShape', 'Foundation', \n",
    "#                    'Heating', 'CentralAir', 'ExterCond', 'RoofStyle', 'LandSlope', \n",
    "#                    'Street', 'RoofMatl', 'Condition2', 'Utilities']\n",
    "\n",
    "# Drop the specified columns from X\n",
    "#_X = X.drop(columns=columns_to_drop)\n",
    "rms_log = cv_rmse(pipeline, X, y)\n",
    "print(\"cat boost regressor: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "# rms_log = cv_rmse(xgb_pipeline, X, y)\n",
    "# print(\"xgb_pipeline regressor: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "# rms_log = cv_rmse(gbr, _X, y)\n",
    "# print(\"gbr regressor: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "# rms_log = cv_rmse(lreg_pipeline, X, y)\n",
    "# print(\"lreg_pipeline regressor: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "# rms_log = cv_rmse(lasso, X, y)\n",
    "# print(\"lasso regressor: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "#rms_log = cv_rmse(elasticnet, X, y)\n",
    "# print(\"elasticnet: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "# rms_log = cv_rmse(svr, X, y)\n",
    "# print(\"svr: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))\n",
    "# rms_log = cv_rmse(xgboost, X, y)\n",
    "# print(\"xgboost: {:.4f} ({:.4f})\\n\".format(rms_log.mean(), rms_log.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_log"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_features_to_select=40 : cat boost regressor: 0.1190 (0.0189)\n",
    "n_features_to_select=45 : cat boost regressor: 0.1179 (0.0185)\n",
    "n_features_to_select=50 : cat boost regressor: 0.1181 (0.0198)\n",
    "n_features_to_select=55 : cat boost regressor: 0.1175 (0.0197)\n",
    "n_features_to_select=60 : cat boost regressor: 0.1174 (0.0189)\n",
    "n_features_to_select=65 : cat boost regressor: 0.1190 (0.0206)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "taking out columns with 1-2 unique values: cat boost regressor: 0.1147 (0.0146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_features_to_select=10 : gbr regressor: 0.1162 (0.0156)\n",
    "n_features_to_select=15 : gbr regressor: 0.1162 (0.0156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Finally predict on the competition test data using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit again now on full data_set to improve results\n",
    "# y_pred_lr = LinearModelCV(X,y,'LinearModel',False,testset_df)\n",
    "y_pred_cat = CatTransllModelCV(X,y,'CatTransll',False,testset_df)\n",
    "#y_pred_cat\n",
    "# y_pred_catcat = CatKeepAllModelCV(X,y,'CatKeepAll',False,testset_df)\n",
    "# y_pred_comb = (y_pred_lr + y_pred_cat + y_pred_catcat)/3\n",
    "# y_pred_lr = np.exp(y_pred_lr)\n",
    "y_pred_cat =np.exp(y_pred_cat)\n",
    "# y_pred_catcat = np.exp(y_pred_catcat)\n",
    "# y_pred_comb = np.exp(y_pred_comb)\n",
    " \n",
    "\n",
    "# output = pd.DataFrame({'Id': id_file,'SalePrice': y_pred_lr.squeeze()})\n",
    "# output.to_csv('./project/submission_lr.csv', index=False)\n",
    "# output.head()\n",
    "\n",
    "# output = pd.DataFrame({'Id': id_file,'SalePrice': y_pred_cat.squeeze()})\n",
    "# output.to_csv('./project/submission_cat.csv', index=False)\n",
    "# output.head()\n",
    "\n",
    "# output = pd.DataFrame({'Id': id_file,'SalePrice': y_pred_catcat.squeeze()})\n",
    "# output.to_csv('./project/submission_Cat_KeepAll.csv', index=False)\n",
    "# output.head()\n",
    "\n",
    "# output = pd.DataFrame({'Id': id_file,'SalePrice': y_pred_comb.squeeze()})\n",
    "# output.to_csv('./project/submission_comp.csv', index=False)\n",
    "# output.head()\n",
    "\n",
    "y_pred = y_pred_cat\n",
    "output = pd.DataFrame({'Id': id_file,'SalePrice': y_pred.squeeze()})\n",
    "output.to_csv('./project/submission.csv', index=False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df[abs(np.log(y_pred_catcat)- np.log(y_pred_lr))>0.4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(np.log(y_pred_catcat), np.log(y_pred_lr),True) \n",
    "plot_pred(np.log(y_pred_catcat), np.log(y_pred_cat),True) \n",
    "plot_pred(np.log(y_pred_catcat), np.log(y_pred_comb),True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Fit the scaler to the pivot table data and transform the data\n",
    "# standardized_data = pd.DataFrame(scaler.fit_transform(numeric_features_df), columns=numeric_features_df.columns, index=numeric_features_df.index)\n",
    "# lof_clf = LocalOutlierFactor()\n",
    "# lof_clf.fit_predict(standardized_data)\n",
    "# lof_scores = lof_clf.negative_outlier_factor_\n",
    "# lof_scores = pd.DataFrame({'score': lof_scores}, index=numeric_features_df.index)\n",
    "# combined_df = pd.concat([lof_scores, numeric_features_df], axis=1).sort_values('score')\n",
    "# combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
